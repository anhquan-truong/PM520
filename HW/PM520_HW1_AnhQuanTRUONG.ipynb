{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhquan-truong/PM520/blob/main/HW/PM520_HW1_AnhQuanTRUONG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r94B4C5cpi8I"
      },
      "source": [
        "# Homework 1. Linear regression and normal equations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XknGDH_1Kohu"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as rdm\n",
        "import jax.numpy.linalg as jnpla\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7TX02bf92rV"
      },
      "source": [
        "# 1. Linear model simulation\n",
        "In class we defined a Python function that simulates $N$ $P\\times 1$ variables $X$ (i.e. an $N \\times P$ matrix $X$) and outcome $y$ as a linear function of $X$. Please include its definition here and use for problem 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEreYqjJNudL"
      },
      "source": [
        "Given $N \\times P$ matrix $X$, a $P \\times 1$ vector $\\beta$, and $N \\times 1$ outcome vector $y$, and a random variabl $\\epsilon$, with $\\mathbb{E}[\\epsilon]=0$ and $Var(\\epsilon) = \\sigma^2$. Then, we can describe the $y$ as a linear function of $X$ as\n",
        "\n",
        "$$\n",
        "y = X\\times \\beta + \\epsilon\\\\\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s1CpkFZh6Y7p",
        "outputId": "03740036-5884-4b69-cca6-1d3ec0f09eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of epsilon: 0.9396470785140991\n",
            " Var of epsilon: 158.33473205566406\n"
          ]
        }
      ],
      "source": [
        "def sim_linear_reg(key, N, P, r2=0.5):\n",
        "  key, b_key = rdm.split(key)\n",
        "  b = rdm.normal(b_key, shape=(P,))\n",
        "\n",
        "  key, X_key = rdm.split(key)\n",
        "  X = rdm.normal(X_key, shape = (N, P))\n",
        "\n",
        "  y_hat = X @ b # this is the predicted y without error eps\n",
        "  s2pred = jnp.var(y_hat)\n",
        "  s2tot = s2pred/r2 # s2tot = s2pred + s2e\n",
        "  s2e =( s2tot - s2pred)\n",
        "\n",
        "  key, e_key = rdm.split(key)\n",
        "  eps = rdm.normal(e_key, shape = (N,)) * jnp.sqrt(s2e)\n",
        "  y = y_hat + eps\n",
        "  return y, y_hat, b, X, eps\n",
        "\n",
        "seed = 912\n",
        "key = rdm.PRNGKey(seed) # creating key from seed\n",
        "\n",
        "N, P = 1000, 150 # a matrix 1000 x 150\n",
        "\n",
        "y, y_hat, b, X, eps = sim_linear_reg(key, N, P, r2=0.5)\n",
        "\n",
        "#Double check eps\n",
        "print(f\"Mean of epsilon: {jnp.mean(eps)}\\n Var of epsilon: {jnp.var(eps)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq2qsE137hUK"
      },
      "source": [
        "# 2. Just-in time decorator and ordinary least squares\n",
        "Complete the definition of `ordinary_least_squares` below, that estimates the effect and its standard error. `@jit` wraps a function to perform just-in-time compilation, which boosts computational performance/speed.\n",
        "\n",
        "Compare the times of with and without JIT\n",
        "Hint: use [`block_until_ready()`](https://jax.readthedocs.io/en/latest/_autosummary/jax.block_until_ready.html) to get correct timing estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3OWo_ixyh7Y",
        "outputId": "e317ae2a-8b1c-4c92-d199-f4a7d80f43f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4.50251251e-01 -1.52883574e-01  3.14414471e-01  6.80672228e-02\n",
            "  1.28357494e+00  1.76152444e+00 -4.74031895e-01 -1.39597678e+00\n",
            " -7.98884481e-02 -8.96839857e-01  3.49870294e-01 -2.20914531e+00\n",
            "  1.69369769e+00 -2.27455348e-01  1.13967729e+00 -1.47309911e+00\n",
            "  1.51594985e+00 -7.81703591e-01  1.00653470e+00 -8.47649097e-01\n",
            "  1.00606728e+00  7.41412103e-01 -2.59430408e-01 -1.71335351e+00\n",
            " -8.58722329e-01  5.26010871e-01  2.40069509e+00 -1.58846056e+00\n",
            "  1.67933500e+00  1.24910533e+00 -5.66803336e-01  1.70093790e-01\n",
            "  3.76371473e-01  1.71797872e+00  1.33770967e+00  5.92871234e-02\n",
            "  3.70338678e-01  8.80754888e-01 -6.68964863e-01  1.21331072e+00\n",
            " -3.95349264e-01 -1.06813574e+00 -3.53555024e-01 -8.05687383e-02\n",
            "  8.37355196e-01 -1.10281193e+00 -1.52880931e+00 -1.47320771e+00\n",
            " -3.56925368e-01 -1.51822805e+00 -8.36969793e-01 -1.57295883e+00\n",
            "  1.04633021e+00  1.55464292e+00 -1.33921242e+00  1.22519922e+00\n",
            " -1.79591924e-01  4.88310516e-01  1.62782475e-01  5.51790930e-02\n",
            "  1.22392941e+00  1.92954585e-01 -1.49891877e+00  5.68797231e-01\n",
            " -1.66427016e+00 -5.67327254e-02  1.14983007e-01 -5.09591818e-01\n",
            "  6.94076896e-01 -4.95352224e-02 -5.90137541e-01 -1.94711816e+00\n",
            "  1.53395069e+00 -3.93626541e-02  4.37309481e-02 -7.15483785e-01\n",
            " -8.95118535e-01 -1.03227270e+00  1.71699092e-01 -1.26942933e+00\n",
            "  5.28073497e-03 -1.52534735e+00 -2.90400186e-03 -8.09986591e-01\n",
            " -4.78812426e-01  1.56287384e+00 -5.21579146e-01 -7.23496437e-01\n",
            "  1.13150939e-01  2.13569927e+00 -1.15712118e+00 -1.92440224e+00\n",
            " -9.21102464e-01 -8.08814883e-01  1.65499389e+00  7.65298665e-01\n",
            "  3.15516144e-01  1.29258605e-02 -1.63332418e-01 -9.06714145e-03\n",
            "  4.97726738e-01  2.89974242e-01 -5.41982591e-01 -8.74532938e-01\n",
            "  1.57844961e+00 -6.02508605e-01 -5.38453162e-02 -7.46402383e-01\n",
            " -1.07246017e+00  8.17541871e-03 -2.69593298e-01  1.92606688e-01\n",
            " -8.51430833e-01  4.30572987e-01  5.14661849e-01  1.66482115e+00\n",
            "  1.09244370e+00 -2.45274857e-01  1.87464023e+00 -1.43180573e+00\n",
            " -2.11568069e+00  5.83807766e-01  9.24143255e-01  1.76502395e+00\n",
            "  1.16286731e+00 -8.71348739e-01 -1.53109956e+00  3.90110922e+00\n",
            "  6.93657279e-01 -9.01388347e-01  3.44203174e-01  8.90030384e-01\n",
            "  1.40696418e+00  1.63378870e+00  2.22332329e-01 -7.46815681e-01\n",
            " -6.20323896e-01 -1.92127824e+00  3.27488750e-01  7.84983039e-01\n",
            "  7.74107277e-02 -1.48445874e-01 -1.14337206e+00 -4.93364394e-01\n",
            "  1.75506341e+00  8.10130477e-01  3.07119578e-01  9.82547641e-01\n",
            " -1.16154158e+00 -1.45488441e+00]\n",
            "[0.4240419  0.42817765 0.4209169  0.41366175 0.4367606  0.43111983\n",
            " 0.4212228  0.42992827 0.43478054 0.42646414 0.4322536  0.4424688\n",
            " 0.41686812 0.43342555 0.41224837 0.43623808 0.45289254 0.40809742\n",
            " 0.4362324  0.4068837  0.4316374  0.42047998 0.4164003  0.42130294\n",
            " 0.42729893 0.42335275 0.40474668 0.41680542 0.43151426 0.42557484\n",
            " 0.41518193 0.41597205 0.41716883 0.43940854 0.43715036 0.4248238\n",
            " 0.44099444 0.4234995  0.42282814 0.42700866 0.42304748 0.4169084\n",
            " 0.41995525 0.4271977  0.41514426 0.41810325 0.4443941  0.4245786\n",
            " 0.4418787  0.4213462  0.42099    0.41934085 0.414493   0.4246889\n",
            " 0.41664425 0.42787325 0.43292955 0.4296754  0.4361905  0.42478248\n",
            " 0.42670217 0.42182934 0.42146653 0.41564828 0.42743516 0.41346735\n",
            " 0.4324602  0.43293986 0.42176515 0.42230237 0.42921475 0.41159898\n",
            " 0.4416876  0.4209487  0.4150157  0.43780553 0.4233733  0.43445823\n",
            " 0.4451168  0.42558157 0.4229273  0.42696518 0.41524935 0.42696765\n",
            " 0.43672335 0.43121836 0.42629498 0.42819545 0.43708742 0.4379656\n",
            " 0.424182   0.43753454 0.43927035 0.41571733 0.4374534  0.4265325\n",
            " 0.4345679  0.43112004 0.4260215  0.4240892  0.45245507 0.41602245\n",
            " 0.42818773 0.4052774  0.41232422 0.4266434  0.4284171  0.42889547\n",
            " 0.42824274 0.42240578 0.4127485  0.42197087 0.43280467 0.4309406\n",
            " 0.4303716  0.4316503  0.42918327 0.427997   0.43210462 0.42872542\n",
            " 0.41677853 0.426967   0.44171786 0.4413858  0.4225292  0.42613146\n",
            " 0.4268278  0.43338466 0.44984084 0.43899345 0.42940953 0.44475546\n",
            " 0.43661886 0.4174064  0.4300551  0.41355604 0.4151954  0.42766705\n",
            " 0.4216023  0.4348273  0.42117146 0.42881885 0.42227298 0.4220326\n",
            " 0.40648964 0.42678756 0.41113907 0.40852842 0.44543174 0.4048742 ]\n",
            "16.4 ms ± 5.54 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "10.2 ms ± 3.7 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "\n",
        "from jax import jit\n",
        "\n",
        "\n",
        "def ordinary_least_squares(X, y):\n",
        "  N, P = X.shape\n",
        "  XtX = X.T @ X\n",
        "  b_hat = jnpla.inv(XtX) @ (X.T@y)\n",
        "\n",
        "  s2_e = jnp.sum(jnp.square(y - X @ b_hat)) / (N - P)\n",
        "  # Corrected se_b_hat calculation: sqrt of diagonal of (s2_e * (X'X)^-1)\n",
        "  se_b_hat = jnp.sqrt(jnp.diag(s2_e * jnpla.inv(X.T @ X)))\n",
        "  return b_hat, se_b_hat\n",
        "\n",
        "jit_ordinary_least_squares = jit(ordinary_least_squares)\n",
        "\n",
        "N, P = 1000, 150 # a matrix 1000 x 150\n",
        "y, y_hat, b, X, eps = sim_linear_reg(key, N, P, r2=0.5)\n",
        "\n",
        "b_hat, se_b_hat = jit_ordinary_least_squares(X,y)\n",
        "print(b_hat)\n",
        "print(se_b_hat)\n",
        "\n",
        "%timeit ordinary_least_squares(X,y)[0].block_until_ready()\n",
        "%timeit jit_ordinary_least_squares(X,y)[0].block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNGJ7Yij8gBt"
      },
      "source": [
        "# 3. OLS derivation\n",
        "Assume that $y = X \\beta + \\epsilon$ where $y$ is $N \\times 1$ vector, $X$ is an $N \\times P$ matrix where $P < N$ and $\\epsilon$ is a random variable such that $\\mathbb{E}[\\epsilon_i] = 0$ and $\\mathbb{V}[\\epsilon_i] = \\sigma^2$ for all $i = 1 \\dots n$. Derive the OLS \"normal equations\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_GI3GZNlt1q"
      },
      "source": [
        "The goal is to find $\\beta$ such that the residual sum of square is minimal (RSS), or the sun of square of $\\epsilon$ is minimal. The $RSS(\\beta)$ is\n",
        "\n",
        "$$RSS(\\beta)=\\sum_{i=1}^n (y_i - x_i^T\\beta)^2$$\n",
        "\n",
        "We want to find\n",
        "\n",
        "$$\\beta^*=argmin \\ RSS(\\beta)$$\n",
        "\n",
        "**Approach**: We find stationary point, i.e. the point with zero gradients. We take the derivative of $RSS(\\beta)$ with respect to $\\beta$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\frac{\\partial RSS(\\beta)}{\\partial \\beta} &= 2\\sum_{i=1}^n (x_i^T\\beta-y_i)x_i \\\\\n",
        "&=2\\sum_{i=1}^n (x_i^T x_i \\beta - x_i y_i) \\\\\n",
        "&=2\\sum_{i=1}^n (x_i^T \\beta x_i - x_i y_i) \\\\\n",
        "&=2\\sum_{i=1}^n (x_i x_i^T) \\beta - 2\\sum_{i=1}^n (x_i y_i) \\\\\n",
        "&=2\\sum_{i=1}^n (x_i x_i^T) \\beta - 2\\sum_{i=1}^n (x_i y_i) \\\\\n",
        "&=2[(X^T X) \\beta - (X^T Y)] \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "From that we have\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\nabla RSS(\\beta) &= 0 \\iff 2[(X^T X) \\beta - (X^T Y)]  = 0 \\iff \\beta = (X^T X)^{-1} (X^T Y)\\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "assuming $(X^T X)$ is invertible.\n",
        "\n",
        "Now we calculate the standard error of $\\beta$\n",
        "\n",
        "From above, we have\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\hat{\\beta} &= (X^T X)^{-1} (X^T Y) \\\\\n",
        "&= (X^T X)^{-1} X^T (X \\beta + \\epsilon)\\\\\n",
        "&= (X^T X)^{-1} X^T X \\beta + (X^T X)^{-1} X^T \\epsilon\\\\\n",
        "&= In \\beta + (X^T X)^{-1} X^T \\epsilon\\\\\n",
        "\\implies \\beta - \\hat{\\beta} &= (X^T X)^{-1} X^T \\epsilon\\\\\n",
        "\\implies Var(\\hat{\\beta}) &= Var[(X^T X)^{-1} X^T \\epsilon]\\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Apply variances rule for a matrix-vector mulilplication $Var(Ax) = AVar(X)A^T$, we have\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "Var(\\hat{\\beta}) &= [(X^T X)^{-1} X^T]\\ Var(\\epsilon)\\ [(X^T X)^{-1} X^T]^T\\\\\n",
        "&= [(X^T X)^{-1} X^T]\\  Var(\\epsilon)\\ X [(X^T X)^{-1}]^T\\\\\n",
        "&= [(X^T X)^{-1} X^T]\\ Var(\\epsilon)\\ X [(X^T X)^T]^{-1}\\\\\n",
        "\\implies Var(\\hat{\\beta}) &= [(X^T X)^{-1} X^T]\\ Var(\\epsilon)\\ X (X^T X)^{-1}\\\\\n",
        "\\end{align*}\n",
        "$$\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}