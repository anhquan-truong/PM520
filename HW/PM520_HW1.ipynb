{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhquan-truong/PM520/blob/main/HW/PM520_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1. Linear regression and normal equations"
      ],
      "metadata": {
        "id": "r94B4C5cpi8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as rdm\n",
        "import jax.numpy.linalg as jnpla\n"
      ],
      "metadata": {
        "id": "XknGDH_1Kohu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Linear model simulation\n",
        "In class we defined a Python function that simulates $N$ $P\\times 1$ variables $X$ (i.e. an $N \\times P$ matrix $X$) and outcome $y$ as a linear function of $X$. Please include its definition here and use for problem 2."
      ],
      "metadata": {
        "id": "G7TX02bf92rV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given $P \\times N$, non-singular matrix $X$, and $P \\times N$ matrix B with outcome $y$, we can describe the $y$ as a linear function of $X$ as $$A \\times X=y.$$"
      ],
      "metadata": {
        "id": "GEreYqjJNudL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sim_linear_reg(key, N, P, r2=0.5):\n",
        "  key, x_key = rdm.split(key)\n",
        "  A = rdm.normal(x_key, shape=(P, N))\n",
        "  X = rdm.normal(key, shape = (N, P))\n",
        "  y = A @ x\n",
        "  return A, x, y\n",
        "\n",
        "seed = 912\n",
        "key = rdm.PRNGKey(seed) # creating key from seed\n",
        "print(key) # Print only the single key\n",
        "\n",
        "N = 100 # variables\n",
        "P = 10 # dimensions - or number of features\n",
        "\n",
        "A, x, y = sim_linear_reg(key, N, P, r2=0.5) # Pass the single 'key' instead of 'sim_key'\n",
        "\n",
        "# Solving using algebraic approach\n",
        "Ainv = jnpla.pinv(A) #Using Moore-Penrose pseudo-inverse because of non-square matrix\n",
        "is_same  = jnp.allclose(jnp.eye(P,P), A@Ainv)\n",
        "print(f\"Identity check? {is_same}\")"
      ],
      "metadata": {
        "id": "s1CpkFZh6Y7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e1f06d-23d4-4c22-8d56-630d231f764a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0 912]\n",
            "Identity check? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Just-in time decorator and ordinary least squares\n",
        "Complete the definition of `ordinary_least_squares` below, that estimates the effect and its standard error. `@jit` wraps a function to perform just-in-time compilation, which boosts computational performance/speed.\n",
        "\n",
        "Compare the times of with and without JIT\n",
        "Hint: use [`block_until_ready()`](https://jax.readthedocs.io/en/latest/_autosummary/jax.block_until_ready.html) to get correct timing estimates."
      ],
      "metadata": {
        "id": "Bq2qsE137hUK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3OWo_ixyh7Y"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "\n",
        "from jax import jit\n",
        "\n",
        "\n",
        "def ordinary_least_squares(X, y):\n",
        "  \"\"\"\n",
        "  computes the OLS solution to linear system y ~ X.\n",
        "  Returns a tuple of $\\hat{beta}$ and $\\text{se}(\\hat{beta})$.\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "jit_ordinary_least_squares = jit(ordinary_least_squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. OLS derivation\n",
        "Assume that $y = X \\beta + \\epsilon$ where $y$ is $N \\times 1$ vector, $X$ is an $N \\times P$ matrix where $P < N$ and $\\epsilon$ is a random variable such that $\\mathbb{E}[\\epsilon_i] = 0$ and $\\mathbb{V}[\\epsilon_i] = \\sigma^2$ for all $i = 1 \\dots n$. Derive the OLS \"normal equations\"."
      ],
      "metadata": {
        "id": "pNGJ7Yij8gBt"
      }
    }
  ]
}